# 紫色灯条PnP位姿估计

本代码实现了使用PnP算法来确定机器人与紫色灯条的相对位置。

## 功能特性

1. **HSV颜色检测**: 检测紫色灯条
2. **轮廓过滤**: 基于面积、长宽比等参数过滤矩形灯条
3. **角点提取**: 从轮廓中提取有序的角点
4. **PnP算法**: 计算3D位姿（位置和旋转）
5. **位姿发布**: 将计算的位姿通过ROS话题发布
6. **可视化**: 在图像上显示检测结果和坐标轴

## 核心算法

### 1. PnP算法原理
PnP (Perspective-n-Point) 算法通过已知的3D点和对应的2D图像点来求解相机位姿。本实现中：

- **3D模型点**: 假设灯条为矩形，定义4个角点的3D坐标
- **2D图像点**: 从检测到的轮廓中提取的角点
- **相机参数**: 内参矩阵和畸变系数

### 2. 算法流程
1. HSV颜色空间转换和阈值化
2. 轮廓检测和过滤
3. 角点提取和排序
4. PnP求解位姿
5. 结果发布和可视化

## 参数配置

### 相机参数
```yaml
camera_fx: 800.0      # 焦距x
camera_fy: 800.0      # 焦距y  
camera_cx: 320.0      # 主点x
camera_cy: 240.0      # 主点y
dist_coeffs: [0.0, 0.0, 0.0, 0.0, 0.0]  # 畸变系数
```

### 灯条3D模型
```yaml
lightstrip_width: 0.2    # 灯条宽度（米）
lightstrip_height: 0.05  # 灯条高度（米）
```

### 检测参数
```yaml
# HSV颜色阈值
h_min: 125    # 紫色色调范围
h_max: 155

# 轮廓过滤
area_min: 100.0         # 最小面积
area_max: 50000.0       # 最大面积
area_ratio_min: 0.6     # 面积填充比例
aspect_ratio_min: 0.5   # 长宽比范围
aspect_ratio_max: 2.0
```

## 使用方法

### 1. 启动仿真环境
```bash
roslaunch conqu_lightstrip_sim strip.launch
```

### 2. 查看检测结果
- 图像窗口显示检测结果
- 绿色矩形框：检测到的灯条
- 蓝色圆点：灯条中心
- 彩色坐标轴：PnP计算的3D坐标系

### 3. 获取位姿信息
```bash
rostopic echo /lightstrip_pose
```

位姿消息包含：
- `position`: 灯条在相机坐标系中的位置 (x, y, z)
- `orientation`: 灯条的旋转（四元数表示）

## 坐标系说明

- **相机坐标系**: 
  - X轴：右
  - Y轴：下  
  - Z轴：前（光轴方向）
- **灯条坐标系**: 以灯条中心为原点的3D坐标系

## 调试和优化

### 1. 相机标定
为获得准确的位姿估计，需要标定相机获得准确的内参和畸变系数。

### 2. 参数调优
- 根据实际灯条尺寸调整 `lightstrip_width` 和 `lightstrip_height`
- 根据光照条件调整HSV阈值
- 根据距离调整面积过滤参数

### 3. 角点检测优化
- 确保检测到的角点顺序正确
- 可以添加更严格的角点验证

## 输出信息

程序会在终端输出：
- 相机参数信息
- 灯条3D模型信息  
- 检测到的位姿信息（位置和距离）

## 注意事项

1. 确保灯条在相机视野内且清晰可见
2. 光照条件会影响HSV检测效果
3. 灯条的实际尺寸必须准确设置
4. 相机参数需要通过标定获得
5. 算法假设灯条为平面矩形，适用于标准形状的灯条
